[
    {
        "loss": 0.028,
        "grad_norm": 0.14784586429595947,
        "learning_rate": 4.960014714585033e-05,
        "epoch": 0.023991171248980377,
        "step": 500
    },
    {
        "loss": 0.032,
        "grad_norm": 0.45733335614204407,
        "learning_rate": 4.920029429170065e-05,
        "epoch": 0.04798234249796075,
        "step": 1000
    },
    {
        "loss": 0.0326,
        "grad_norm": 0.046834204345941544,
        "learning_rate": 4.880044143755098e-05,
        "epoch": 0.07197351374694112,
        "step": 1500
    },
    {
        "loss": 0.0295,
        "grad_norm": 0.35802480578422546,
        "learning_rate": 4.8400588583401314e-05,
        "epoch": 0.0959646849959215,
        "step": 2000
    },
    {
        "loss": 0.0301,
        "grad_norm": 0.3410513997077942,
        "learning_rate": 4.800073572925164e-05,
        "epoch": 0.11995585624490188,
        "step": 2500
    },
    {
        "loss": 0.0354,
        "grad_norm": 0.35516202449798584,
        "learning_rate": 4.760088287510196e-05,
        "epoch": 0.14394702749388225,
        "step": 3000
    },
    {
        "loss": 0.0332,
        "grad_norm": 0.4571223258972168,
        "learning_rate": 4.7201030020952295e-05,
        "epoch": 0.16793819874286262,
        "step": 3500
    },
    {
        "loss": 0.0314,
        "grad_norm": 0.39568427205085754,
        "learning_rate": 4.680117716680262e-05,
        "epoch": 0.191929369991843,
        "step": 4000
    },
    {
        "loss": 0.0299,
        "grad_norm": 0.18602734804153442,
        "learning_rate": 4.6401324312652944e-05,
        "epoch": 0.21592054124082338,
        "step": 4500
    },
    {
        "loss": 0.0317,
        "grad_norm": 0.3383837044239044,
        "learning_rate": 4.6001471458503275e-05,
        "epoch": 0.23991171248980375,
        "step": 5000
    },
    {
        "loss": 0.0316,
        "grad_norm": 0.0017138465773314238,
        "learning_rate": 4.56016186043536e-05,
        "epoch": 0.2639028837387841,
        "step": 5500
    },
    {
        "loss": 0.0306,
        "grad_norm": 0.7057880163192749,
        "learning_rate": 4.520176575020393e-05,
        "epoch": 0.2878940549877645,
        "step": 6000
    },
    {
        "loss": 0.0319,
        "grad_norm": 0.444840669631958,
        "learning_rate": 4.4801912896054256e-05,
        "epoch": 0.31188522623674486,
        "step": 6500
    },
    {
        "loss": 0.0317,
        "grad_norm": 0.26498040556907654,
        "learning_rate": 4.440206004190458e-05,
        "epoch": 0.33587639748572523,
        "step": 7000
    },
    {
        "loss": 0.0307,
        "grad_norm": 0.4685044288635254,
        "learning_rate": 4.4002207187754905e-05,
        "epoch": 0.3598675687347056,
        "step": 7500
    },
    {
        "loss": 0.0363,
        "grad_norm": 0.1557459980249405,
        "learning_rate": 4.3602354333605236e-05,
        "epoch": 0.383858739983686,
        "step": 8000
    },
    {
        "loss": 0.032,
        "grad_norm": 1.269729733467102,
        "learning_rate": 4.320250147945557e-05,
        "epoch": 0.4078499112326664,
        "step": 8500
    },
    {
        "loss": 0.034,
        "grad_norm": 0.2775358259677887,
        "learning_rate": 4.280264862530589e-05,
        "epoch": 0.43184108248164677,
        "step": 9000
    },
    {
        "loss": 0.0341,
        "grad_norm": 0.29536980390548706,
        "learning_rate": 4.2402795771156217e-05,
        "epoch": 0.45583225373062713,
        "step": 9500
    },
    {
        "loss": 0.0341,
        "grad_norm": 0.7394131422042847,
        "learning_rate": 4.200294291700654e-05,
        "epoch": 0.4798234249796075,
        "step": 10000
    },
    {
        "loss": 0.0321,
        "grad_norm": 0.19405168294906616,
        "learning_rate": 4.160309006285687e-05,
        "epoch": 0.5038145962285879,
        "step": 10500
    },
    {
        "loss": 0.0327,
        "grad_norm": 0.3192533850669861,
        "learning_rate": 4.12032372087072e-05,
        "epoch": 0.5278057674775682,
        "step": 11000
    },
    {
        "loss": 0.0306,
        "grad_norm": 2.0246574878692627,
        "learning_rate": 4.080338435455752e-05,
        "epoch": 0.5517969387265487,
        "step": 11500
    },
    {
        "loss": 0.0316,
        "grad_norm": 0.55736243724823,
        "learning_rate": 4.040353150040785e-05,
        "epoch": 0.575788109975529,
        "step": 12000
    },
    {
        "loss": 0.0317,
        "grad_norm": 0.002188058802857995,
        "learning_rate": 4.000367864625818e-05,
        "epoch": 0.5997792812245094,
        "step": 12500
    },
    {
        "loss": 0.0315,
        "grad_norm": 0.34151121973991394,
        "learning_rate": 3.960382579210851e-05,
        "epoch": 0.6237704524734897,
        "step": 13000
    },
    {
        "loss": 0.0307,
        "grad_norm": 0.2551986873149872,
        "learning_rate": 3.9203972937958833e-05,
        "epoch": 0.6477616237224701,
        "step": 13500
    },
    {
        "loss": 0.0296,
        "grad_norm": 0.3112063705921173,
        "learning_rate": 3.880412008380916e-05,
        "epoch": 0.6717527949714505,
        "step": 14000
    },
    {
        "loss": 0.0324,
        "grad_norm": 1.6580435037612915,
        "learning_rate": 3.840426722965948e-05,
        "epoch": 0.6957439662204309,
        "step": 14500
    },
    {
        "loss": 0.0317,
        "grad_norm": 0.0017178639536723495,
        "learning_rate": 3.8004414375509814e-05,
        "epoch": 0.7197351374694112,
        "step": 15000
    },
    {
        "loss": 0.0321,
        "grad_norm": 0.5085362195968628,
        "learning_rate": 3.7604561521360145e-05,
        "epoch": 0.7437263087183916,
        "step": 15500
    },
    {
        "loss": 0.0293,
        "grad_norm": 0.44188883900642395,
        "learning_rate": 3.720470866721047e-05,
        "epoch": 0.767717479967372,
        "step": 16000
    },
    {
        "loss": 0.0335,
        "grad_norm": 0.4900588095188141,
        "learning_rate": 3.6804855813060794e-05,
        "epoch": 0.7917086512163524,
        "step": 16500
    },
    {
        "loss": 0.0329,
        "grad_norm": 0.35133591294288635,
        "learning_rate": 3.640500295891112e-05,
        "epoch": 0.8156998224653328,
        "step": 17000
    },
    {
        "loss": 0.0308,
        "grad_norm": 0.3599754869937897,
        "learning_rate": 3.600515010476145e-05,
        "epoch": 0.8396909937143131,
        "step": 17500
    },
    {
        "loss": 0.032,
        "grad_norm": 0.24733372032642365,
        "learning_rate": 3.5605297250611775e-05,
        "epoch": 0.8636821649632935,
        "step": 18000
    },
    {
        "loss": 0.0295,
        "grad_norm": 0.26753824949264526,
        "learning_rate": 3.5205444396462106e-05,
        "epoch": 0.8876733362122738,
        "step": 18500
    },
    {
        "loss": 0.0306,
        "grad_norm": 0.2823728024959564,
        "learning_rate": 3.480559154231243e-05,
        "epoch": 0.9116645074612543,
        "step": 19000
    },
    {
        "loss": 0.0315,
        "grad_norm": 0.14893478155136108,
        "learning_rate": 3.4405738688162755e-05,
        "epoch": 0.9356556787102346,
        "step": 19500
    },
    {
        "loss": 0.0309,
        "grad_norm": 0.2606603801250458,
        "learning_rate": 3.400588583401309e-05,
        "epoch": 0.959646849959215,
        "step": 20000
    },
    {
        "loss": 0.0295,
        "grad_norm": 0.0008657244616188109,
        "learning_rate": 3.360603297986341e-05,
        "epoch": 0.9836380212081954,
        "step": 20500
    },
    {
        "eval_loss": 0.030441399663686752,
        "eval_model_preparation_time": 0.001,
        "eval_accuracy_thresh": 0.9804587364196777,
        "eval_runtime": 191.5818,
        "eval_samples_per_second": 435.125,
        "eval_steps_per_second": 27.2,
        "epoch": 1.0,
        "step": 20841
    },
    {
        "loss": 0.026,
        "grad_norm": 0.2792617082595825,
        "learning_rate": 3.3206180125713736e-05,
        "epoch": 1.0076291924571759,
        "step": 21000
    },
    {
        "loss": 0.0292,
        "grad_norm": 0.20836874842643738,
        "learning_rate": 3.280632727156406e-05,
        "epoch": 1.031620363706156,
        "step": 21500
    },
    {
        "loss": 0.0305,
        "grad_norm": 0.3693545162677765,
        "learning_rate": 3.24064744174144e-05,
        "epoch": 1.0556115349551365,
        "step": 22000
    },
    {
        "loss": 0.029,
        "grad_norm": 0.36223646998405457,
        "learning_rate": 3.200662156326472e-05,
        "epoch": 1.079602706204117,
        "step": 22500
    },
    {
        "loss": 0.0295,
        "grad_norm": 0.31860196590423584,
        "learning_rate": 3.160676870911505e-05,
        "epoch": 1.1035938774530973,
        "step": 23000
    },
    {
        "loss": 0.0299,
        "grad_norm": 0.17074507474899292,
        "learning_rate": 3.120691585496537e-05,
        "epoch": 1.1275850487020775,
        "step": 23500
    },
    {
        "loss": 0.0282,
        "grad_norm": 0.3239019513130188,
        "learning_rate": 3.0807063000815704e-05,
        "epoch": 1.151576219951058,
        "step": 24000
    },
    {
        "loss": 0.0291,
        "grad_norm": 0.15983563661575317,
        "learning_rate": 3.0407210146666025e-05,
        "epoch": 1.1755673912000384,
        "step": 24500
    },
    {
        "loss": 0.0304,
        "grad_norm": 0.20923054218292236,
        "learning_rate": 3.000735729251636e-05,
        "epoch": 1.1995585624490188,
        "step": 25000
    },
    {
        "loss": 0.0263,
        "grad_norm": 0.23953638970851898,
        "learning_rate": 2.9607504438366684e-05,
        "epoch": 1.223549733697999,
        "step": 25500
    },
    {
        "loss": 0.0291,
        "grad_norm": 0.32039937376976013,
        "learning_rate": 2.9207651584217012e-05,
        "epoch": 1.2475409049469794,
        "step": 26000
    },
    {
        "loss": 0.0282,
        "grad_norm": 0.30954307317733765,
        "learning_rate": 2.8807798730067337e-05,
        "epoch": 1.2715320761959599,
        "step": 26500
    },
    {
        "loss": 0.0281,
        "grad_norm": 0.347116619348526,
        "learning_rate": 2.8407945875917665e-05,
        "epoch": 1.2955232474449403,
        "step": 27000
    },
    {
        "loss": 0.0293,
        "grad_norm": 0.31111401319503784,
        "learning_rate": 2.800809302176799e-05,
        "epoch": 1.3195144186939207,
        "step": 27500
    },
    {
        "loss": 0.0296,
        "grad_norm": 0.0013358804862946272,
        "learning_rate": 2.7608240167618317e-05,
        "epoch": 1.3435055899429011,
        "step": 28000
    },
    {
        "loss": 0.0289,
        "grad_norm": 0.2982923686504364,
        "learning_rate": 2.720838731346865e-05,
        "epoch": 1.3674967611918813,
        "step": 28500
    },
    {
        "loss": 0.0273,
        "grad_norm": 0.0038504297845065594,
        "learning_rate": 2.6808534459318973e-05,
        "epoch": 1.3914879324408618,
        "step": 29000
    },
    {
        "loss": 0.0296,
        "grad_norm": 0.3995908200740814,
        "learning_rate": 2.64086816051693e-05,
        "epoch": 1.4154791036898422,
        "step": 29500
    },
    {
        "loss": 0.0297,
        "grad_norm": 0.3631088137626648,
        "learning_rate": 2.6008828751019625e-05,
        "epoch": 1.4394702749388224,
        "step": 30000
    },
    {
        "loss": 0.0287,
        "grad_norm": 0.0009031061781570315,
        "learning_rate": 2.5608975896869953e-05,
        "epoch": 1.4634614461878028,
        "step": 30500
    },
    {
        "loss": 0.028,
        "grad_norm": 0.4135047495365143,
        "learning_rate": 2.5209123042720278e-05,
        "epoch": 1.4874526174367833,
        "step": 31000
    },
    {
        "loss": 0.0281,
        "grad_norm": 0.1894078552722931,
        "learning_rate": 2.4809270188570606e-05,
        "epoch": 1.5114437886857637,
        "step": 31500
    },
    {
        "loss": 0.0293,
        "grad_norm": 1.2102000713348389,
        "learning_rate": 2.4409417334420934e-05,
        "epoch": 1.535434959934744,
        "step": 32000
    },
    {
        "loss": 0.0279,
        "grad_norm": 0.0007342322496697307,
        "learning_rate": 2.4009564480271262e-05,
        "epoch": 1.5594261311837245,
        "step": 32500
    },
    {
        "loss": 0.0271,
        "grad_norm": 0.30260246992111206,
        "learning_rate": 2.360971162612159e-05,
        "epoch": 1.5834173024327047,
        "step": 33000
    },
    {
        "loss": 0.0277,
        "grad_norm": 0.045591920614242554,
        "learning_rate": 2.3209858771971914e-05,
        "epoch": 1.6074084736816852,
        "step": 33500
    },
    {
        "loss": 0.0297,
        "grad_norm": 0.32306021451950073,
        "learning_rate": 2.2810005917822242e-05,
        "epoch": 1.6313996449306654,
        "step": 34000
    },
    {
        "loss": 0.0288,
        "grad_norm": 0.2516527771949768,
        "learning_rate": 2.241015306367257e-05,
        "epoch": 1.6553908161796458,
        "step": 34500
    },
    {
        "loss": 0.0281,
        "grad_norm": 0.002516565378755331,
        "learning_rate": 2.2010300209522898e-05,
        "epoch": 1.6793819874286262,
        "step": 35000
    },
    {
        "loss": 0.0281,
        "grad_norm": 0.2013251930475235,
        "learning_rate": 2.1610447355373223e-05,
        "epoch": 1.7033731586776066,
        "step": 35500
    },
    {
        "loss": 0.0269,
        "grad_norm": 0.0009664861136116087,
        "learning_rate": 2.121059450122355e-05,
        "epoch": 1.727364329926587,
        "step": 36000
    },
    {
        "loss": 0.0283,
        "grad_norm": 0.540860652923584,
        "learning_rate": 2.081074164707388e-05,
        "epoch": 1.7513555011755675,
        "step": 36500
    },
    {
        "loss": 0.0291,
        "grad_norm": 0.1663178652524948,
        "learning_rate": 2.0410888792924203e-05,
        "epoch": 1.775346672424548,
        "step": 37000
    },
    {
        "loss": 0.0301,
        "grad_norm": 0.0008106576278805733,
        "learning_rate": 2.0011035938774535e-05,
        "epoch": 1.7993378436735281,
        "step": 37500
    },
    {
        "loss": 0.0286,
        "grad_norm": 0.37941643595695496,
        "learning_rate": 1.961118308462486e-05,
        "epoch": 1.8233290149225085,
        "step": 38000
    },
    {
        "loss": 0.0263,
        "grad_norm": 0.2442234307527542,
        "learning_rate": 1.9211330230475187e-05,
        "epoch": 1.8473201861714887,
        "step": 38500
    },
    {
        "loss": 0.0299,
        "grad_norm": 0.38259464502334595,
        "learning_rate": 1.881147737632551e-05,
        "epoch": 1.8713113574204692,
        "step": 39000
    },
    {
        "loss": 0.0286,
        "grad_norm": 0.37434127926826477,
        "learning_rate": 1.841162452217584e-05,
        "epoch": 1.8953025286694496,
        "step": 39500
    },
    {
        "loss": 0.028,
        "grad_norm": 0.3887002170085907,
        "learning_rate": 1.8011771668026168e-05,
        "epoch": 1.91929369991843,
        "step": 40000
    },
    {
        "loss": 0.0272,
        "grad_norm": 0.22898206114768982,
        "learning_rate": 1.7611918813876492e-05,
        "epoch": 1.9432848711674104,
        "step": 40500
    },
    {
        "loss": 0.029,
        "grad_norm": 0.35930266976356506,
        "learning_rate": 1.7212065959726824e-05,
        "epoch": 1.9672760424163909,
        "step": 41000
    },
    {
        "loss": 0.0269,
        "grad_norm": 0.6475554704666138,
        "learning_rate": 1.6812213105577148e-05,
        "epoch": 1.9912672136653713,
        "step": 41500
    },
    {
        "eval_loss": 0.029908116906881332,
        "eval_model_preparation_time": 0.001,
        "eval_accuracy_thresh": 0.9804927110671997,
        "eval_runtime": 186.6015,
        "eval_samples_per_second": 446.738,
        "eval_steps_per_second": 27.926,
        "epoch": 2.0,
        "step": 41682
    },
    {
        "loss": 0.0271,
        "grad_norm": 0.20635053515434265,
        "learning_rate": 1.6412360251427476e-05,
        "epoch": 2.0152583849143517,
        "step": 42000
    },
    {
        "loss": 0.0263,
        "grad_norm": 0.0006811931380070746,
        "learning_rate": 1.6012507397277804e-05,
        "epoch": 2.0392495561633317,
        "step": 42500
    },
    {
        "loss": 0.0267,
        "grad_norm": 0.3891230821609497,
        "learning_rate": 1.561265454312813e-05,
        "epoch": 2.063240727412312,
        "step": 43000
    },
    {
        "loss": 0.0263,
        "grad_norm": 0.31189975142478943,
        "learning_rate": 1.5212801688978457e-05,
        "epoch": 2.0872318986612926,
        "step": 43500
    },
    {
        "loss": 0.0266,
        "grad_norm": 0.4719627797603607,
        "learning_rate": 1.4812948834828783e-05,
        "epoch": 2.111223069910273,
        "step": 44000
    },
    {
        "loss": 0.0247,
        "grad_norm": 0.6997491717338562,
        "learning_rate": 1.4413095980679112e-05,
        "epoch": 2.1352142411592534,
        "step": 44500
    },
    {
        "loss": 0.0259,
        "grad_norm": 0.22250357270240784,
        "learning_rate": 1.4013243126529437e-05,
        "epoch": 2.159205412408234,
        "step": 45000
    },
    {
        "loss": 0.0271,
        "grad_norm": 0.48051226139068604,
        "learning_rate": 1.3613390272379763e-05,
        "epoch": 2.1831965836572143,
        "step": 45500
    },
    {
        "loss": 0.0276,
        "grad_norm": 0.0005429351585917175,
        "learning_rate": 1.3213537418230093e-05,
        "epoch": 2.2071877549061947,
        "step": 46000
    },
    {
        "loss": 0.0277,
        "grad_norm": 0.0006861375295557082,
        "learning_rate": 1.2813684564080419e-05,
        "epoch": 2.231178926155175,
        "step": 46500
    },
    {
        "loss": 0.0274,
        "grad_norm": 0.28881892561912537,
        "learning_rate": 1.2413831709930745e-05,
        "epoch": 2.255170097404155,
        "step": 47000
    },
    {
        "loss": 0.0258,
        "grad_norm": 0.21650372445583344,
        "learning_rate": 1.2013978855781073e-05,
        "epoch": 2.2791612686531355,
        "step": 47500
    },
    {
        "loss": 0.0278,
        "grad_norm": 0.3056914806365967,
        "learning_rate": 1.1614126001631401e-05,
        "epoch": 2.303152439902116,
        "step": 48000
    },
    {
        "loss": 0.0266,
        "grad_norm": 0.45433369278907776,
        "learning_rate": 1.1214273147481728e-05,
        "epoch": 2.3271436111510964,
        "step": 48500
    },
    {
        "loss": 0.0279,
        "grad_norm": 0.4703018367290497,
        "learning_rate": 1.0814420293332054e-05,
        "epoch": 2.351134782400077,
        "step": 49000
    },
    {
        "loss": 0.026,
        "grad_norm": 0.3453260362148285,
        "learning_rate": 1.041456743918238e-05,
        "epoch": 2.375125953649057,
        "step": 49500
    },
    {
        "loss": 0.0277,
        "grad_norm": 0.0005893621710129082,
        "learning_rate": 1.0014714585032708e-05,
        "epoch": 2.3991171248980376,
        "step": 50000
    },
    {
        "loss": 0.0275,
        "grad_norm": 0.00100323383230716,
        "learning_rate": 9.614861730883036e-06,
        "epoch": 2.423108296147018,
        "step": 50500
    },
    {
        "loss": 0.0274,
        "grad_norm": 0.28891634941101074,
        "learning_rate": 9.215008876733362e-06,
        "epoch": 2.447099467395998,
        "step": 51000
    },
    {
        "loss": 0.0264,
        "grad_norm": 0.28668516874313354,
        "learning_rate": 8.81515602258369e-06,
        "epoch": 2.4710906386449785,
        "step": 51500
    },
    {
        "loss": 0.0265,
        "grad_norm": 0.006661539431661367,
        "learning_rate": 8.415303168434016e-06,
        "epoch": 2.495081809893959,
        "step": 52000
    },
    {
        "loss": 0.0265,
        "grad_norm": 0.6411839723587036,
        "learning_rate": 8.015450314284344e-06,
        "epoch": 2.5190729811429393,
        "step": 52500
    },
    {
        "loss": 0.0267,
        "grad_norm": 0.0007394503918476403,
        "learning_rate": 7.6155974601346715e-06,
        "epoch": 2.5430641523919197,
        "step": 53000
    },
    {
        "loss": 0.0278,
        "grad_norm": 0.21227264404296875,
        "learning_rate": 7.215744605984998e-06,
        "epoch": 2.5670553236409,
        "step": 53500
    },
    {
        "loss": 0.0268,
        "grad_norm": 0.3508017063140869,
        "learning_rate": 6.815891751835325e-06,
        "epoch": 2.5910464948898806,
        "step": 54000
    },
    {
        "loss": 0.026,
        "grad_norm": 0.24243442714214325,
        "learning_rate": 6.416038897685651e-06,
        "epoch": 2.615037666138861,
        "step": 54500
    },
    {
        "loss": 0.0269,
        "grad_norm": 0.14777711033821106,
        "learning_rate": 6.016186043535979e-06,
        "epoch": 2.6390288373878414,
        "step": 55000
    },
    {
        "loss": 0.0268,
        "grad_norm": 0.30390664935112,
        "learning_rate": 5.616333189386306e-06,
        "epoch": 2.6630200086368214,
        "step": 55500
    },
    {
        "loss": 0.0257,
        "grad_norm": 0.29811838269233704,
        "learning_rate": 5.2164803352366325e-06,
        "epoch": 2.6870111798858023,
        "step": 56000
    },
    {
        "loss": 0.0262,
        "grad_norm": 0.4869861602783203,
        "learning_rate": 4.8166274810869605e-06,
        "epoch": 2.7110023511347823,
        "step": 56500
    },
    {
        "loss": 0.0267,
        "grad_norm": 0.0006857481203041971,
        "learning_rate": 4.4167746269372876e-06,
        "epoch": 2.7349935223837627,
        "step": 57000
    },
    {
        "loss": 0.0269,
        "grad_norm": 0.0005167532945051789,
        "learning_rate": 4.016921772787615e-06,
        "epoch": 2.758984693632743,
        "step": 57500
    },
    {
        "loss": 0.0277,
        "grad_norm": 0.48624640703201294,
        "learning_rate": 3.6170689186379414e-06,
        "epoch": 2.7829758648817235,
        "step": 58000
    },
    {
        "loss": 0.0257,
        "grad_norm": 0.3462259769439697,
        "learning_rate": 3.217216064488268e-06,
        "epoch": 2.806967036130704,
        "step": 58500
    },
    {
        "loss": 0.0257,
        "grad_norm": 0.38631293177604675,
        "learning_rate": 2.8173632103385956e-06,
        "epoch": 2.8309582073796844,
        "step": 59000
    },
    {
        "loss": 0.0251,
        "grad_norm": 0.3066289722919464,
        "learning_rate": 2.4175103561889227e-06,
        "epoch": 2.854949378628665,
        "step": 59500
    },
    {
        "loss": 0.0269,
        "grad_norm": 0.5053062438964844,
        "learning_rate": 2.0176575020392498e-06,
        "epoch": 2.878940549877645,
        "step": 60000
    },
    {
        "loss": 0.0266,
        "grad_norm": 0.4322194457054138,
        "learning_rate": 1.6178046478895765e-06,
        "epoch": 2.9029317211266257,
        "step": 60500
    },
    {
        "loss": 0.0304,
        "grad_norm": 0.4868059456348419,
        "learning_rate": 1.2179517937399038e-06,
        "epoch": 2.9269228923756057,
        "step": 61000
    },
    {
        "loss": 0.0267,
        "grad_norm": 0.2556896507740021,
        "learning_rate": 8.180989395902308e-07,
        "epoch": 2.950914063624586,
        "step": 61500
    },
    {
        "loss": 0.0273,
        "grad_norm": 0.4475960433483124,
        "learning_rate": 4.1824608544055795e-07,
        "epoch": 2.9749052348735665,
        "step": 62000
    },
    {
        "loss": 0.0257,
        "grad_norm": 0.0005001734825782478,
        "learning_rate": 1.8393231290884953e-08,
        "epoch": 2.998896406122547,
        "step": 62500
    },
    {
        "eval_loss": 0.0293759573251009,
        "eval_model_preparation_time": 0.001,
        "eval_accuracy_thresh": 0.980734646320343,
        "eval_runtime": 181.7138,
        "eval_samples_per_second": 458.754,
        "eval_steps_per_second": 28.677,
        "epoch": 3.0,
        "step": 62523
    },
    {
        "train_runtime": 8478.6375,
        "train_samples_per_second": 117.984,
        "train_steps_per_second": 7.374,
        "total_flos": 3.313168573356288e+16,
        "train_loss": 0.02896028274046323,
        "epoch": 3.0,
        "step": 62523
    }
]